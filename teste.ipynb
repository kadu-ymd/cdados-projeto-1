{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from __future__ import print_function, unicode_literals\r\n",
    "nltk.download('machado')\r\n",
    "nltk.download('genesis')\r\n",
    "nltk.download('mac_morpho')\r\n",
    "\r\n",
    "from nltk.corpus import machado, mac_morpho, floresta, genesis\r\n",
    "from nltk.text import Text\r\n",
    "from nltk.probability import FreqDist\r\n",
    "from nltk.util import bigrams\r\n",
    "from nltk.misc import babelize_shell\r\n",
    "\r\n",
    "print(\"*** Exemplos introdut√≥rios do livro NLTK em Portugu√™s ***\")\r\n",
    "print(\"Carregando ptext1...ptext4 e psent1...ptext4\")\r\n",
    "print(\"Use 'texts()' ou 'sents()' para listar os materiais de texto ou senten√ßa.\")\r\n",
    "\r\n",
    "ptext1 = Text(machado.words('romance/marm05.txt'), name=\"Mem√≥rias P√≥stumas de Br√°s Cubas (1881)\")\r\n",
    "ptext2 = Text(machado.words('romance/marm08.txt'), name=\"Dom Casmurro (1899)\")\r\n",
    "ptext3 = Text(genesis.words('portuguese.txt'), name=\"G√™nesis\")\r\n",
    "ptext4 = Text(mac_morpho.words('mu94se01.txt'), name=\"Folha de Sao Paulo (1994)\")\r\n",
    "\r\n",
    "def texts():\r\n",
    "    print(\"ptext1:\", ptext1.name)\r\n",
    "    print(\"ptext2:\", ptext2.name)\r\n",
    "    print(\"ptext3:\", ptext3.name)\r\n",
    "    print(\"ptext4:\", ptext4.name)\r\n",
    "\r\n",
    "psent1 = \"o amor da gl√≥ria era a coisa mais verdadeiramente humana que h√° no homem , e , conseq√ºentemente , a sua mais genu√≠na fei√ß√£o .\".split()\r\n",
    "psent2 = \"N√£o consultes dicion√°rios .\".split()\r\n",
    "psent3 = \"No princ√≠pio, criou Deus os c√©us e a terra.\".split()\r\n",
    "psent4 = \"A C√°ritas acredita que outros cubanos devem chegar ao Brasil .\".split()\r\n",
    "\r\n",
    "def sents():\r\n",
    "    print(\"psent1:\", \" \".join(psent1))\r\n",
    "    print(\"psent2:\", \" \".join(psent2))\r\n",
    "    print(\"psent3:\", \" \".join(psent3))\r\n",
    "    print(\"psent4:\", \" \".join(psent4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package machado to C:\\Users\\Paula\n",
      "[nltk_data]     Yamada\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package machado is already up-to-date!\n",
      "[nltk_data] Downloading package genesis to C:\\Users\\Paula\n",
      "[nltk_data]     Yamada\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package genesis is already up-to-date!\n",
      "[nltk_data] Downloading package mac_morpho to C:\\Users\\Paula\n",
      "[nltk_data]     Yamada\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package mac_morpho is already up-to-date!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*** Exemplos introdut√≥rios do livro NLTK em Portugu√™s ***\n",
      "Carregando ptext1...ptext4 e psent1...ptext4\n",
      "Use 'texts()' ou 'sents()' para listar os materiais de texto ou senten√ßa.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import re\r\n",
    "\r\n",
    "text = u'This dog \\U0001f602'\r\n",
    "print(text) # with emoji\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(emoji_pattern.sub(r'', text))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This dog üòÇ\n",
      "This dog \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def cleanup(text):\r\n",
    "    \"\"\"\r\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\r\n",
    "    \"\"\"\r\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\r\n",
    "    pattern = re.compile(punctuation)\r\n",
    "    emojis = \"[\"u\"\\U0001F600-\\U0001F64F\"u\"\\U0001F300-\\U0001F5FF\"u\"\\U0001F680-\\U0001F6FF\"u\"\\U0001F1E0-\\U0001F1FF\"\"]+\"\r\n",
    "    emoji_pattern = re.compile(emojis, flags=re.UNICODE)\r\n",
    "\r\n",
    "    text_subbed = re.sub(pattern, '', text)\r\n",
    "    text_subbed = re.sub(emoji_pattern, '', text)\r\n",
    "    text_subbed = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\r\n",
    "\r\n",
    "    return text_subbed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import functools\r\n",
    "import operator\r\n",
    "import re\r\n",
    "\r\n",
    "import emoji\r\n",
    "\r\n",
    "em = 'Hey üò∑üò∑üò∑'\r\n",
    "em_split_emoji = emoji.get_emoji_regexp().split(em)\r\n",
    "print(em_split_emoji)\r\n",
    "em_split_whitespace = [substr.split() for substr in em_split_emoji]\r\n",
    "em_split = functools.reduce(operator.concat, em_split_whitespace)\r\n",
    "print(em_split)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Hey ', 'üò∑', '', 'üò∑', '', 'üò∑', '']\n",
      "['Hey', 'üò∑', 'üò∑', 'üò∑']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "import nltk\r\n",
    "nltk.download('stopwords')\r\n",
    "\r\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\r\n",
    "stopwords"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Paula\n",
      "[nltk_data]     Yamada\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['de',\n",
       " 'a',\n",
       " 'o',\n",
       " 'que',\n",
       " 'e',\n",
       " '√©',\n",
       " 'do',\n",
       " 'da',\n",
       " 'em',\n",
       " 'um',\n",
       " 'para',\n",
       " 'com',\n",
       " 'n√£o',\n",
       " 'uma',\n",
       " 'os',\n",
       " 'no',\n",
       " 'se',\n",
       " 'na',\n",
       " 'por',\n",
       " 'mais',\n",
       " 'as',\n",
       " 'dos',\n",
       " 'como',\n",
       " 'mas',\n",
       " 'ao',\n",
       " 'ele',\n",
       " 'das',\n",
       " '√†',\n",
       " 'seu',\n",
       " 'sua',\n",
       " 'ou',\n",
       " 'quando',\n",
       " 'muito',\n",
       " 'nos',\n",
       " 'j√°',\n",
       " 'eu',\n",
       " 'tamb√©m',\n",
       " 's√≥',\n",
       " 'pelo',\n",
       " 'pela',\n",
       " 'at√©',\n",
       " 'isso',\n",
       " 'ela',\n",
       " 'entre',\n",
       " 'depois',\n",
       " 'sem',\n",
       " 'mesmo',\n",
       " 'aos',\n",
       " 'seus',\n",
       " 'quem',\n",
       " 'nas',\n",
       " 'me',\n",
       " 'esse',\n",
       " 'eles',\n",
       " 'voc√™',\n",
       " 'essa',\n",
       " 'num',\n",
       " 'nem',\n",
       " 'suas',\n",
       " 'meu',\n",
       " '√†s',\n",
       " 'minha',\n",
       " 'numa',\n",
       " 'pelos',\n",
       " 'elas',\n",
       " 'qual',\n",
       " 'n√≥s',\n",
       " 'lhe',\n",
       " 'deles',\n",
       " 'essas',\n",
       " 'esses',\n",
       " 'pelas',\n",
       " 'este',\n",
       " 'dele',\n",
       " 'tu',\n",
       " 'te',\n",
       " 'voc√™s',\n",
       " 'vos',\n",
       " 'lhes',\n",
       " 'meus',\n",
       " 'minhas',\n",
       " 'teu',\n",
       " 'tua',\n",
       " 'teus',\n",
       " 'tuas',\n",
       " 'nosso',\n",
       " 'nossa',\n",
       " 'nossos',\n",
       " 'nossas',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'esta',\n",
       " 'estes',\n",
       " 'estas',\n",
       " 'aquele',\n",
       " 'aquela',\n",
       " 'aqueles',\n",
       " 'aquelas',\n",
       " 'isto',\n",
       " 'aquilo',\n",
       " 'estou',\n",
       " 'est√°',\n",
       " 'estamos',\n",
       " 'est√£o',\n",
       " 'estive',\n",
       " 'esteve',\n",
       " 'estivemos',\n",
       " 'estiveram',\n",
       " 'estava',\n",
       " 'est√°vamos',\n",
       " 'estavam',\n",
       " 'estivera',\n",
       " 'estiv√©ramos',\n",
       " 'esteja',\n",
       " 'estejamos',\n",
       " 'estejam',\n",
       " 'estivesse',\n",
       " 'estiv√©ssemos',\n",
       " 'estivessem',\n",
       " 'estiver',\n",
       " 'estivermos',\n",
       " 'estiverem',\n",
       " 'hei',\n",
       " 'h√°',\n",
       " 'havemos',\n",
       " 'h√£o',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houveram',\n",
       " 'houvera',\n",
       " 'houv√©ramos',\n",
       " 'haja',\n",
       " 'hajamos',\n",
       " 'hajam',\n",
       " 'houvesse',\n",
       " 'houv√©ssemos',\n",
       " 'houvessem',\n",
       " 'houver',\n",
       " 'houvermos',\n",
       " 'houverem',\n",
       " 'houverei',\n",
       " 'houver√°',\n",
       " 'houveremos',\n",
       " 'houver√£o',\n",
       " 'houveria',\n",
       " 'houver√≠amos',\n",
       " 'houveriam',\n",
       " 'sou',\n",
       " 'somos',\n",
       " 's√£o',\n",
       " 'era',\n",
       " '√©ramos',\n",
       " 'eram',\n",
       " 'fui',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'foram',\n",
       " 'fora',\n",
       " 'f√¥ramos',\n",
       " 'seja',\n",
       " 'sejamos',\n",
       " 'sejam',\n",
       " 'fosse',\n",
       " 'f√¥ssemos',\n",
       " 'fossem',\n",
       " 'for',\n",
       " 'formos',\n",
       " 'forem',\n",
       " 'serei',\n",
       " 'ser√°',\n",
       " 'seremos',\n",
       " 'ser√£o',\n",
       " 'seria',\n",
       " 'ser√≠amos',\n",
       " 'seriam',\n",
       " 'tenho',\n",
       " 'tem',\n",
       " 'temos',\n",
       " 't√©m',\n",
       " 'tinha',\n",
       " 't√≠nhamos',\n",
       " 'tinham',\n",
       " 'tive',\n",
       " 'teve',\n",
       " 'tivemos',\n",
       " 'tiveram',\n",
       " 'tivera',\n",
       " 'tiv√©ramos',\n",
       " 'tenha',\n",
       " 'tenhamos',\n",
       " 'tenham',\n",
       " 'tivesse',\n",
       " 'tiv√©ssemos',\n",
       " 'tivessem',\n",
       " 'tiver',\n",
       " 'tivermos',\n",
       " 'tiverem',\n",
       " 'terei',\n",
       " 'ter√°',\n",
       " 'teremos',\n",
       " 'ter√£o',\n",
       " 'teria',\n",
       " 'ter√≠amos',\n",
       " 'teriam']"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "a62a3330c22067498225200e433f1b8ac4b8d642a79071681a45c428ce3bb911"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}