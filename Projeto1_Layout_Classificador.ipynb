{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nome: Carlos Eduardo Porciuncula Yamada\r\n",
    "\r\n",
    "Nome: Pedro Henrique de Sousa da Silva"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Tweets relevantes:\r\n",
    "    - Críticas à marca ou produtos\r\n",
    "    - Anúncios de eventos\r\n",
    "    - Venda de produtos\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "\r\n",
    "## Escolha do produto\r\n",
    "\r\n",
    "* Produto escolhido: **`Apple`**\r\n",
    "\r\n",
    "  - Apple é uma empresa norte-americana que recentemente anunciou o lançamento de diversos produtos como o iPhone 13 e o Apple Watch 7.\r\n",
    "    A classificação foi feita considerando se o tweet tem relação com a marca ou se faz parte de uma discussão relacionada à empresa: opinião, crítica ou afim."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "\r\n",
    "Carregando algumas bibliotecas:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na falta de alguma das bibliotecas abaixo, descomentar a linha da biblioteca e executar a célula:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# !pip install pandas\r\n",
    "# !pip install matplotlib\r\n",
    "# !pip install numpy\r\n",
    "# !pip install functools\r\n",
    "# !pip install operator\r\n",
    "# !pip install re\r\n",
    "# !pip install emoji\r\n",
    "# !pip install nltk\r\n",
    "# nltk.download('stopwords')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%matplotlib inline\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import emoji\r\n",
    "import functools\r\n",
    "import operator\r\n",
    "import re \r\n",
    "import nltk"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print('Esperamos trabalhar no diretório')\r\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\sjcpe\\OneDrive\\Área de Trabalho\\C.Dados\\Projeto 1\\cdados-projeto-1-1\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "filename = 'Apple.xlsx'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train = dft = pd.read_excel('Apple.xlsx', sheet_name='Treinamento')\r\n",
    "test = dft = pd.read_excel('Apple.xlsx', sheet_name='Teste')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "## Montando um Classificador Naive-Bayes\r\n",
    "\r\n",
    "Aqui criamos funções com os seguintes intuitos:\r\n",
    "- Remoção de pontuação (`função I: cleanup()`);\r\n",
    "- Correção de espaços entre emojis (`função II: separa_emoji()`);\r\n",
    "- Remoção de palavras de parada (ou *stopwords*) (`função III: remove_stopwords()`);\r\n",
    "\r\n",
    "Ao final da montagem, também aplicamos a Suavização de Laplace."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# FUNÇÃO I\r\n",
    "def cleanup(text):\r\n",
    "    \"\"\"\r\n",
    "        Função de limpeza muito simples que troca\r\n",
    "        alguns sinais básicos por espaços\r\n",
    "    \"\"\"\r\n",
    "    pont = '[!-.:?;]' # Note que os sinais [] são delimitadores de um conjunto.\r\n",
    "    pattern = re.compile(pont)\r\n",
    "\r\n",
    "    text_subbed = re.sub(pattern, '', text)\r\n",
    "    text_subbed = re.sub(r'http\\S+', '', text_subbed)\r\n",
    "\r\n",
    "    return text_subbed\r\n",
    "\r\n",
    "# FUNÇÃO II\r\n",
    "def separa_emoji(text):\r\n",
    "    \"\"\"\r\n",
    "        Função que separa emojis em frases\r\n",
    "    \"\"\"\r\n",
    "    em_split_emoji = emoji.get_emoji_regexp().split(text)\r\n",
    "    em_split_whitespace = [substr.split() for substr in em_split_emoji]\r\n",
    "    em_split = functools.reduce(operator.concat, em_split_whitespace)\r\n",
    "    return em_split\r\n",
    "\r\n",
    "# FUNÇÃO III\r\n",
    "def remove_stopwords(lista):\r\n",
    "    \"\"\"\r\n",
    "        Esta função remove palavras de parada,\r\n",
    "        tais como 'as', 'os', entre outras\r\n",
    "    \"\"\"\r\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\r\n",
    "    l = list()\r\n",
    "    for p in lista:\r\n",
    "        if not p in stopwords:\r\n",
    "            l.append(p)\r\n",
    "    return l"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "## Obtenção de valores a partir dos DataFrames"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Criando uma série para contabilizar as frequências relativas de **todos os tweets** da planilha '`Treinamento`' da base de dados:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "lista = list()\r\n",
    "for i in range(train.shape[0]):\r\n",
    "    lista += remove_stopwords(separa_emoji(cleanup(train.Treinamento[i])))\r\n",
    "serie_twt = pd.Series(lista)\r\n",
    "twt_relat = serie_twt.value_counts(True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Elaborando tabelas separadas para os tweets classificados como '`relevantes`' ou '`irrelevantes`':"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "bool_ = train.isin([1])\r\n",
    "\r\n",
    "filtro_r = bool_['Classificação'] == True\r\n",
    "filtro_i = bool_['Classificação'] == False\r\n",
    "\r\n",
    "relevantes = train.loc[filtro_r, :]\r\n",
    "irrelevantes = train.loc[filtro_i, :]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Criando uma série para contabilizar as frequências relativas de **tweets relevantes** e de **tweets irrelevantes** da planilha '`Treinamento`':"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "li_rel = list()\r\n",
    "li_irr = list()\r\n",
    "\r\n",
    "for i in range(relevantes.shape[0]):\r\n",
    "    li_rel += remove_stopwords(separa_emoji(cleanup(relevantes.Treinamento[relevantes.index[i]])))\r\n",
    "\r\n",
    "for i in range(irrelevantes.shape[0]):\r\n",
    "    li_irr += remove_stopwords(separa_emoji(cleanup(irrelevantes.Treinamento[irrelevantes.index[i]])))\r\n",
    "\r\n",
    "serie_rel = pd.Series(li_rel)\r\n",
    "rel_relat = serie_rel.value_counts(True)\r\n",
    "\r\n",
    "serie_irr = pd.Series(li_irr)\r\n",
    "irr_relat = serie_irr.value_counts(True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Criando uma nova coluna na planilha '`Teste`' da base de dados, onde guardaremos os valores `1` ou `0` a partir da análise feita pelo classificador:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "test['SemLaplace'] = ''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classificador - Teorema de Bayes\r\n",
    "\r\n",
    "O parâmetro usado pelo classificador será a comparação da probabilidade de o tweet ser ou não relevante. Isto é, sendo $P(R)$ e $P(I)$ a probabilidade de o tweet ser relevante ou irrelevante, respectivamente, temos:\r\n",
    "\r\n",
    "- $P(R|tweet) > P(I|tweet)$, o tweet é relevante;\r\n",
    "- $P(I|tweet) > P(R|tweet)$, o tweet é irrelevante;\r\n",
    "\r\n",
    "Sabendo que $P(R|tweet) = \\frac{P(tweet|R)P(R)}{P(tweet)}$ e que $P(I|tweet) = \\frac{P(tweet|I)P(I)}{P(tweet)}$, a partir do `Teorema de Naive-Bayes`, podemos calcular $P(tweet|R)$ e $P(tweet|I)$ por:\r\n",
    "\r\n",
    "- $P(tweet|R) = P(palavra_1|R).P(palavra_2|R).P(palavra_3|R)...P(palavra_n|R)$\r\n",
    "- $P(tweet|I) = P(palavra_1|I).P(palavra_2|I).P(palavra_3|I)...P(palavra_n|I)$\r\n",
    "\r\n",
    "Considerando essas afirmações e o fato de que não precisamos de $P(tweet)$ para realizarmos a comparação (denominadores iguais), podemos escrever o seguinte código:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "probR = len(li_rel)/len(lista)\r\n",
    "probI = len(li_irr)/len(lista)\r\n",
    "\r\n",
    "for n in range(test.shape[0]):\r\n",
    "    probTdadoI = 1\r\n",
    "    probTdadoR = 1\r\n",
    "\r\n",
    "    tweet = remove_stopwords(separa_emoji(cleanup(test.Teste[n])))\r\n",
    "\r\n",
    "    for p in tweet:\r\n",
    "        if p in rel_relat:\r\n",
    "            probTdadoR *= rel_relat[p]\r\n",
    "    \r\n",
    "    for p in tweet:\r\n",
    "        if p in irr_relat:\r\n",
    "            probTdadoI *= irr_relat[p]\r\n",
    "    \r\n",
    "    probRdadoT = probTdadoR * probR\r\n",
    "    probIdadoT = probTdadoI * probI\r\n",
    "\r\n",
    "    if probRdadoT > probIdadoT:\r\n",
    "        test.SemLaplace[n] = 1\r\n",
    "    else:\r\n",
    "        test.SemLaplace[n] = 0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-11-903f1c67b194>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.SemLaplace[n] = 1\n",
      "<ipython-input-11-903f1c67b194>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.SemLaplace[n] = 0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Suavização de Laplace\r\n",
    "\r\n",
    "Vamos agora implementar a suavização de Laplace, que consiste em incluir os casos que ocorrem quando alguma palavra não está na nossa base de dados, o que anteriormente não eram consideradas no calculo. \r\n",
    "\r\n",
    "Mas como ela funciona? Bem, através de um equacionamento em que é somado uma unidade ao numero de frequência absoluta de vezes em que a palavras apareceu no denominador, retirando a possibilidade de resultar em 0. Como na fórmula descrita abaixo:\r\n",
    "\r\n",
    "$$P(palavra1|I) = \\frac{F_{AI}+1}{P_{I}+P_p}$$\r\n",
    "\r\n",
    "Onde:\r\n",
    "\r\n",
    "$ F_{AR}$: Frequência absoluta da palavra na categoria relevante\r\n",
    "\r\n",
    "$ F_{AI}$: Frequência absoluta da palavra na categoria irrelevante\r\n",
    "\r\n",
    "$P_{R}$: Todas as palavras pertencentes aos tweets rotulados como relevantes\r\n",
    "\r\n",
    "$P_{I}$: Todas as palavras pertencentes aos tweets rotulados como irrelevantes\r\n",
    "\r\n",
    "$P_p$: Todas as palavras possíveis na base de dados de treinamento\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "Agora vamos aplicar esse algoritmo no nosso projeto!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Guarda as frequências absolutas nas variáveis\r\n",
    "palavras_possiveis = serie_twt.value_counts().shape[0]\r\n",
    "qtd_rel = serie_rel.value_counts().shape[0]\r\n",
    "qtd_irr = serie_irr.value_counts().shape[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "rel_abs = serie_rel.value_counts()\r\n",
    "irr_abs = serie_irr.value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Cria mais uma coluna para salvar a probabilidade utilizando a suavização de laplace\r\n",
    "test['Laplace'] = ''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Realiza o equacionamento para calcular a probabilidade \r\n",
    "for n in range(test.Teste.shape[0]):\r\n",
    "    produtoR = 1\r\n",
    "    tweet = remove_stopwords(separa_emoji(cleanup(test.Teste[n])))\r\n",
    "    for p in tweet:\r\n",
    "        if not p in rel_abs:\r\n",
    "            rel_abs[p] = 0\r\n",
    "        produtoR *= (rel_abs[p] + 1)/(qtd_rel + palavras_possiveis)\r\n",
    "\r\n",
    "    produtoI = 1\r\n",
    "\r\n",
    "    for p in tweet:\r\n",
    "        if not p in irr_abs:\r\n",
    "            irr_abs[p] = 0\r\n",
    "        produtoI *= (irr_abs[p] + 1)/(qtd_irr + palavras_possiveis)\r\n",
    "\r\n",
    "    probRdadoT = produtoR * probR\r\n",
    "    probIdadoT = produtoI * probI\r\n",
    "\r\n",
    "    # Guarda o resultado na coluna \r\n",
    "\r\n",
    "    if probRdadoT > probIdadoT:\r\n",
    "        test.Laplace[n] = 1\r\n",
    "    else:\r\n",
    "        test.Laplace[n] = 0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-15-8220195304f6>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.Laplace[n] = 1\n",
      "<ipython-input-15-8220195304f6>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.Laplace[n] = 0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Verificação de performance\r\n",
    "\r\n",
    " Agora, testamos a qualidade do nosso quassificador a partir de alguns percentuais, nas duas situações a seguir:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* **Sem a Suavização de Laplace**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "b = 0\r\n",
    "for i in range(test.shape[0]):\r\n",
    "    if test.Classificação[i] == test.SemLaplace[i]:\r\n",
    "        b += 1\r\n",
    "\r\n",
    "print(f'- Exatidão: {b/test.shape[0]*100}%')\r\n",
    "print(f'- Porcentagem de erro: {(1 - b/test.shape[0])*100:.1f}%')\r\n",
    "\r\n",
    "# PARA VERDADEIROS POSITIVOS\r\n",
    "vpC = test.Classificação == 1\r\n",
    "vpN = test.SemLaplace == 1\r\n",
    "\r\n",
    "# PARA FALSOS POSITIVOS\r\n",
    "fpC = test.Classificação == 0\r\n",
    "fpN = test.SemLaplace == 1\r\n",
    "\r\n",
    "# PARA VERDADEIROS NEGATIVOS\r\n",
    "vnC = test.Classificação == 0\r\n",
    "vnN = test.SemLaplace == 0\r\n",
    "\r\n",
    "# PARA FALSOS NEGATIVOS\r\n",
    "fnC = test.Classificação == 1\r\n",
    "fnN = test.SemLaplace == 0\r\n",
    "\r\n",
    "vp = (test.Teste.loc[vpC & vpN].count()/vpC.sum())*100\r\n",
    "fp = (test.Teste.loc[fpC & fpN].count()/fpC.sum())*100\r\n",
    "vn = (test.Teste.loc[vnC & vnN].count()/vnC.sum())*100\r\n",
    "fn = (test.Teste.loc[fnC & fnN].count()/fnC.sum())*100\r\n",
    "\r\n",
    "print(f'- Verdadeiros positivos (tweets relevantes classificados como relevantes): {vp:.1f}%\\n'\r\n",
    "      f'- Falsos positivos (tweets irrelevantes classificados como relevantes): {fp:.1f}%\\n'\r\n",
    "      f'- Verdadeiros negativos (tweets irrelevantes classificados como irrelevantes): {vn:.1f}%\\n'\r\n",
    "      f'- Falsos negativos (tweets relevantes classificados como irrelevantes): {fn:.1f}%\\n')\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- Exatidão: 46.5%\n",
      "- Porcentagem de erro: 53.5%\n",
      "- Verdadeiros positivos (tweets relevantes classificados como relevantes): 41.0%\n",
      "- Falsos positivos (tweets irrelevantes classificados como relevantes): 48.0%\n",
      "- Verdadeiros negativos (tweets irrelevantes classificados como irrelevantes): 52.0%\n",
      "- Falsos negativos (tweets relevantes classificados como irrelevantes): 59.0%\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# EM RELAÇÃO AO TOTAL\r\n",
    "a = 0\r\n",
    "for i in range(test.shape[0]):\r\n",
    "    if test.Classificação[i] == test.SemLaplace[i]:\r\n",
    "        a += 1\r\n",
    "\r\n",
    "print(f'- Exatidão: {a/test.shape[0]*100}%')\r\n",
    "print(f'- Porcentagem de erro: {(1 - a/test.shape[0])*100:.1f}%')\r\n",
    "\r\n",
    "# VERDADEIROS POSITIVOS\r\n",
    "a = 0\r\n",
    "for i in range(test.shape[0]):\r\n",
    "    if test.Classificação[i] == 1 and test.SemLaplace[i] == 1:\r\n",
    "        a += 1\r\n",
    "print(f'- Verdadeiros positivos (relevantes): {a/test.shape[0]*100}%')\r\n",
    "\r\n",
    "# FALSOS POSITIVOS\r\n",
    "a = 0\r\n",
    "for i in range(test.shape[0]):\r\n",
    "    if test.Classificação[i] == 0 and test.SemLaplace[i] == 1:\r\n",
    "        a += 1\r\n",
    "print(f'- Falsos positivos (relevantes): {a/test.shape[0]*100:.1f}%')\r\n",
    "\r\n",
    "# VERDADEIROS NEGATIVOS\r\n",
    "a = 0\r\n",
    "for i in range(test.shape[0]):\r\n",
    "    if test.Classificação[i] == 0 and test.SemLaplace[i] == 0:\r\n",
    "        a += 1\r\n",
    "print(f'- Verdadeiros negativos (irrelevantes): {a/test.shape[0]*100}%')\r\n",
    "\r\n",
    "# FALSOS NEGATIVOS\r\n",
    "a = 0\r\n",
    "for i in range(test.shape[0]):\r\n",
    "    if test.Classificação[i] == 1 and test.SemLaplace[i] == 0:\r\n",
    "        a += 1\r\n",
    "print(f'- Falsos negativos (irrelevantes): {a/test.shape[0]*100}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- Exatidão: 46.5%\n",
      "- Porcentagem de erro: 53.5%\n",
      "- Verdadeiros positivos (relevantes): 20.5%\n",
      "- Falsos positivos (relevantes): 24.0%\n",
      "- Verdadeiros negativos (irrelevantes): 26.0%\n",
      "- Falsos negativos (irrelevantes): 29.5%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* **Com a Suavização de Laplace**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "a = 0\r\n",
    "for i in range(test.shape[0]):\r\n",
    "    if test.Classificação[i] == test.Laplace[i]:\r\n",
    "        a += 1\r\n",
    "\r\n",
    "print(f'- Exatidão: {a/test.shape[0]*100}%')\r\n",
    "print(f'- Porcentagem de erro: {(1 - a/test.shape[0])*100:.1f}%')\r\n",
    "\r\n",
    "# PARA VERDADEIROS POSITIVOS\r\n",
    "vpC = test.Classificação == 1\r\n",
    "vpL = test.Laplace == 1\r\n",
    "\r\n",
    "# PARA FALSOS POSITIVOS\r\n",
    "fpC = test.Classificação == 0\r\n",
    "fpL = test.Laplace == 1\r\n",
    "\r\n",
    "# PARA VERDADEIROS NEGATIVOS\r\n",
    "vnC = test.Classificação == 0\r\n",
    "vnL = test.Laplace == 0\r\n",
    "\r\n",
    "# PARA FALSOS NEGATIVOS\r\n",
    "fnC = test.Classificação == 1\r\n",
    "fnL = test.Laplace == 0\r\n",
    "\r\n",
    "vp = (test.Teste.loc[vpC & vpL].count()/vpC.sum())*100\r\n",
    "fp = (test.Teste.loc[fpC & fpL].count()/fpC.sum())*100\r\n",
    "vn = (test.Teste.loc[vnC & vnL].count()/vnC.sum())*100\r\n",
    "fn = (test.Teste.loc[fnC & fnL].count()/fnC.sum())*100\r\n",
    "\r\n",
    "print(f'- Verdadeiros positivos (tweets relevantes classificados como relevantes): {vp:.1f}%\\n'\r\n",
    "      f'- Falsos positivos (tweets irrelevantes classificados como relevantes): {fp:.1f}%\\n'\r\n",
    "      f'- Verdadeiros negativos (tweets irrelevantes classificados como irrelevantes): {vn:.1f}%\\n'\r\n",
    "      f'- Falsos negativos (tweets relevantes classificados como irrelevantes): {fn:.1f}%\\n')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- Exatidão: 69.5%\n",
      "- Porcentagem de erro: 30.5%\n",
      "- Verdadeiros positivos (tweets relevantes classificados como relevantes): 96.0%\n",
      "- Falsos positivos (tweets irrelevantes classificados como relevantes): 57.0%\n",
      "- Verdadeiros negativos (tweets irrelevantes classificados como irrelevantes): 43.0%\n",
      "- Falsos negativos (tweets relevantes classificados como irrelevantes): 4.0%\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# EM RELAÇÃO AO TOTAL\r\n",
    "a = 0\r\n",
    "for i in range(test.shape[0]):\r\n",
    "    if test.Classificação[i] == test.Laplace[i]:\r\n",
    "        a += 1\r\n",
    "\r\n",
    "print(f'- Exatidão: {a/test.shape[0]*100}%')\r\n",
    "print(f'- Porcentagem de erro: {(1 - a/test.shape[0])*100:.1f}%')\r\n",
    "\r\n",
    "# VERDADEIROS POSITIVOS\r\n",
    "a = 0\r\n",
    "for i in range(test.shape[0]):\r\n",
    "    if test.Classificação[i] == 1 and test.Laplace[i] == 1:\r\n",
    "        a += 1\r\n",
    "print(f'- Verdadeiros positivos (relevantes): {a/test.shape[0]*100}%')\r\n",
    "\r\n",
    "# FALSOS POSITIVOS\r\n",
    "a = 0\r\n",
    "for i in range(test.shape[0]):\r\n",
    "    if test.Classificação[i] == 0 and test.Laplace[i] == 1:\r\n",
    "        a += 1\r\n",
    "print(f'- Falsos positivos (relevantes): {a/test.shape[0]*100:.1f}%')\r\n",
    "\r\n",
    "# VERDADEIROS NEGATIVOS\r\n",
    "a = 0\r\n",
    "for i in range(test.shape[0]):\r\n",
    "    if test.Classificação[i] == 0 and test.Laplace[i] == 0:\r\n",
    "        a += 1\r\n",
    "print(f'- Verdadeiros negativos (irrelevantes): {a/test.shape[0]*100}%')\r\n",
    "\r\n",
    "# FALSOS NEGATIVOS\r\n",
    "a = 0\r\n",
    "for i in range(test.shape[0]):\r\n",
    "    if test.Classificação[i] == 1 and test.Laplace[i] == 0:\r\n",
    "        a += 1\r\n",
    "print(f'- Falsos negativos (irrelevantes): {a/test.shape[0]*100}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- Exatidão: 69.5%\n",
      "- Porcentagem de erro: 30.5%\n",
      "- Verdadeiros positivos (relevantes): 48.0%\n",
      "- Falsos positivos (relevantes): 28.5%\n",
      "- Verdadeiros negativos (irrelevantes): 21.5%\n",
      "- Falsos negativos (irrelevantes): 2.0%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Concluindo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparando os percentuais \r\n",
    "\r\n",
    "Analisando os dados obtidos a partir dos cálculos acima, temos que:\r\n",
    "\r\n",
    "A exatidão/porcentagem de erro são dois parâmetros complementares que nos ajudam a perceber a qualidade de nossa classificação de modo geral. \r\n",
    "\r\n",
    "* Sem a suavização de Laplace percebemos que a porcentagem de erro, que foi calculada a partir da exatidão do classificador ($erro = 1 - exatidão$), foi razoavelmente alta, indicando que nessa primeira situação o nosso classificador ainda poderia ser aperfeiçoado;\r\n",
    "\r\n",
    "* Com a suavização de Laplace percebemos que a porcentagem de erro diminiu, o que nos levou a concluir que a qualidade do classificador está mais adequada.\r\n",
    "\r\n",
    "As porcentagem de verdadeiros e falsos positivos/negativos são outros indicadores que explicitam a qualidade do nosso classificador. Assim temos:\r\n",
    "\r\n",
    "* Em relação ao total de classificações (relevantes + irrelevantes), ao total de tweets classificados como relevantes e ao total de tweets classificados como irrelevantes:\r\n",
    "\r\n",
    "    - Sem a suavização de Laplace, podemos observar que a porcentagem de classificações feitas de forma incorreta é relativamente alta quando comparada a outras porcentagens (verdadeiros posivos/negativos);\r\n",
    "\r\n",
    "    - Com a suavização de Laplace, obtivemos uma porcentagem de verdadeiros positivos/negativos mais adequada para mostrar que, nessa situação, o nosso classificador está mais sofisticado.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mensagens com dupla negação e sarcasmo \r\n",
    "\r\n",
    "O nosso classificador não compreende tweets que contanham sarcasmo ou negação, pois a probabilidade é calculado com base nas palavras que compõe o tweet, ou seja, o tweet será classificado como relevante ou irrelevante independentemente da presença de dupla negação ou sarcasmo."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Por que não usar o próprio classificador para gerar mais amostras de treinamento\r\n",
    "\r\n",
    "O classificador foi construído a partir de uma base de dados contendo os tweets para treinamento. Na possibilidade de uma realimentação da base de dados utilizando a mesma base, gerará um viés que fará com que os novos dados sejam classificados de forma inadequada. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Novos cenários para o classificador\r\n",
    "\r\n",
    "*  Recomendação de produtos com base no histórico de pesquisa do usúario;\r\n",
    "*  Para a separação de email tomando como base o seu conteúdo, por exemplo, classificar o email como spam;\r\n",
    "*  O corretor automático de digitação, o qual utiliza uma base de dados das palavras que mais digita."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Possíveis melhorias\r\n",
    "\r\n",
    "Poderiam ser usados outros métodos disponíveis na biblioteca `NLTK`, como a lemmatização e a deriavação de palavras (lemmatization e stemming, respectivamente), além de aplicar outras técnicas de limpeza nos tweets. Também podemos aumentar nossa base de dados da planilha treinamento, para aumentar a quantidade de informações que o classificador possui para classificar o tweet como relevante ou irrelevante."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "## Aperfeiçoamento:\r\n",
    "\r\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\r\n",
    "\r\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\r\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\r\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\r\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\r\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\r\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\r\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Referências"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "\r\n",
    "## Referências usadas no Projeto\r\n",
    "\r\n",
    "- [Biblioteca NLTK](https://www.nltk.org)\r\n",
    "\r\n",
    "- [Biblioteca Emoji](https://pypi.org/project/emoji/)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "86dd5e921b40ab2bcc1d5d6c13ec93fcb5ce3ad363a352e9d190522a8cf20aa6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}